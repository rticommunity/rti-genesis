#!/usr/bin/env python3
"""
Real Weather Agent with LLM-based Natural Language Processing

This agent demonstrates the CORRECT pattern for Genesis agents:
- Uses OpenAI GPT-4.1 for natural language understanding
- Uses LLM tool calls to access weather APIs
- No regex parsing or keyword matching
- Real API integration with proper error handling

Architecture:
User Request ‚Üí LLM (GPT-4.1) ‚Üí Tool Calls ‚Üí Real APIs ‚Üí LLM Response

Copyright (c) 2025, RTI & Jason Upchurch
"""

import asyncio
import json
import logging
import os
import sys
import time
from typing import Dict, Any, Optional
from datetime import datetime

# Add the parent directory to the path so we can import genesis_lib
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))

from genesis_lib.monitored_agent import MonitoredAgent

# OpenAI import for LLM calls
try:
    import openai
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False
    print("‚ùå CRITICAL: openai not available. Install with: pip install openai")

# Optional aiohttp import for API calls
try:
    import aiohttp
    HAS_AIOHTTP = True
except ImportError:
    HAS_AIOHTTP = False
    print("‚ùå CRITICAL: aiohttp not available. Install with: pip install aiohttp")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LLMWeatherAgent(MonitoredAgent):
    """
    LLM-powered weather agent with proper natural language processing.
    Uses OpenAI GPT-4.1 for understanding and tool calls for API access.
    """
    
    def __init__(self, api_key: Optional[str] = None, openai_api_key: Optional[str] = None):
        super().__init__(
            agent_name="WeatherExpert",
            base_service_name="WeatherService",
            agent_type="SPECIALIZED_AGENT",
            agent_id="llm_weather_specialist",
            description="LLM-powered weather agent with OpenAI GPT-4.1 and real API integration",
            enable_agent_communication=True
        )
        
        # Get API keys from environment or parameters - BOTH REQUIRED FOR REAL OPERATION
        self.weather_api_key = api_key or os.getenv('OPENWEATHERMAP_API_KEY')
        self.openai_api_key = openai_api_key or os.getenv('OPENAI_API_KEY')
        
        if not self.weather_api_key:
            error_msg = "‚ùå CRITICAL: No OpenWeatherMap API key provided - REAL API REQUIRED"
            logger.error(error_msg)
            raise ValueError(error_msg)
            
        if not self.openai_api_key:
            error_msg = "‚ùå CRITICAL: No OpenAI API key provided - LLM REQUIRED"
            logger.error(error_msg)
            raise ValueError(error_msg)
            
        if not HAS_OPENAI:
            error_msg = "‚ùå CRITICAL: openai package not available - LLM REQUIRED"
            logger.error(error_msg)
            raise ImportError(error_msg)
            
        if not HAS_AIOHTTP:
            error_msg = "‚ùå CRITICAL: aiohttp package not available - API calls REQUIRED"
            logger.error(error_msg)
            raise ImportError(error_msg)
        
        # Initialize OpenAI client
        openai.api_key = self.openai_api_key
        self.openai_client = openai.AsyncOpenAI(api_key=self.openai_api_key)
        
        # Weather API configuration
        self.base_url = "https://api.openweathermap.org/data/2.5"
        self.session: Optional[aiohttp.ClientSession] = None
        
        logger.info("‚úÖ LLM Weather Agent initialized with REAL APIs")
        logger.info(f"üå§Ô∏è OpenWeatherMap API: {'‚úÖ REAL KEY' if self.weather_api_key else '‚ùå MISSING'}")
        logger.info(f"ü§ñ OpenAI API: {'‚úÖ REAL KEY' if self.openai_api_key else '‚ùå MISSING'}")

    def get_agent_capabilities(self):
        """Return agent capabilities for discovery"""
        return {
            "agent_type": "specialized",
            "specializations": ["weather", "meteorology", "climate", "llm_powered"],
            "capabilities": [
                "current_weather", "weather_forecast", "weather_alerts", 
                "temperature_analysis", "precipitation_forecast", "weather_conditions",
                "humidity_check", "wind_speed", "atmospheric_pressure",
                "natural_language_processing", "location_extraction", "weather_classification"
            ],
            "classification_tags": [
                "weather", "temperature", "forecast", "rain", "snow", "storm", "climate",
                "humidity", "wind", "pressure", "sunny", "cloudy", "precipitation", "conditions",
                "meteorology", "celsius", "fahrenheit", "degrees", "hot", "cold", "warm", "cool",
                "overcast", "clear", "llm", "gpt", "natural_language"
            ],
            "model_info": {
                "type": "llm_powered_agent",
                "llm_model": "gpt-4.1-preview",
                "data_source": "OpenWeatherMap API",
                "processing": "natural_language_understanding",
                "fallback": "none_real_apis_only"
            },
            "default_capable": False,
            "performance_metrics": {
                "avg_response_time": 3.5,
                "accuracy_score": 98.0,
                "availability": 99.9,
                "data_freshness": "real_time"
            }
        }

    async def _process_request(self, request: Any) -> Dict[str, Any]:
        """Process request from MonitoredAgent base class"""
        # Convert request to dict if needed
        if hasattr(request, '__dict__'):
            request_dict = request.__dict__
        else:
            request_dict = request
        
        return await self.process_weather_request_with_llm(request_dict)

    async def process_weather_request_with_llm(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """Process weather requests using LLM with tool calls - THE CORRECT PATTERN"""
        message = request.get('message', '')
        conversation_id = request.get('conversation_id', '')
        
        try:
            logger.info(f"ü§ñ Processing weather request with LLM: {message}")
            
            # Define weather tools for the LLM
            tools = [
                {
                    "type": "function",
                    "function": {
                        "name": "get_current_weather",
                        "description": "Get current weather conditions for a specific location",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "location": {
                                    "type": "string",
                                    "description": "The city and state/country, e.g. 'Denver, Colorado' or 'London, UK'"
                                }
                            },
                            "required": ["location"]
                        }
                    }
                },
                {
                    "type": "function",
                    "function": {
                        "name": "get_weather_forecast",
                        "description": "Get weather forecast for a specific location",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "location": {
                                    "type": "string",
                                    "description": "The city and state/country, e.g. 'Denver, Colorado' or 'London, UK'"
                                }
                            },
                            "required": ["location"]
                        }
                    }
                }
            ]
            
            # Call LLM with tools
            response = await self.openai_client.chat.completions.create(
                model="gpt-4-1106-preview",  # GPT-4.1
                messages=[
                    {
                        "role": "system",
                        "content": """You are a weather expert agent. When users ask about weather, use the provided tools to get real weather data. 
                        
                        IMPORTANT: 
                        - Always extract the location correctly from natural language
                        - Use get_current_weather for current conditions
                        - Use get_weather_forecast for future weather
                        - Provide detailed, helpful responses
                        - If no location is specified, ask for clarification"""
                    },
                    {
                        "role": "user", 
                        "content": message
                    }
                ],
                tools=tools,
                tool_choice="auto",
                temperature=0.1
            )
            
            # Process LLM response and tool calls
            assistant_message = response.choices[0].message
            
            if assistant_message.tool_calls:
                # LLM wants to make tool calls - execute them
                logger.info(f"üîß LLM requesting {len(assistant_message.tool_calls)} tool call(s)")
                
                tool_results = []
                for tool_call in assistant_message.tool_calls:
                    function_name = tool_call.function.name
                    function_args = json.loads(tool_call.function.arguments)
                    
                    logger.info(f"üõ†Ô∏è Executing tool call: {function_name}({function_args})")
                    
                    if function_name == "get_current_weather":
                        result = await self._get_current_weather_api(function_args["location"])
                        tool_results.append({
                            "tool_call_id": tool_call.id,
                            "role": "tool",
                            "content": json.dumps(result)
                        })
                    elif function_name == "get_weather_forecast":
                        result = await self._get_forecast_api(function_args["location"])
                        tool_results.append({
                            "tool_call_id": tool_call.id,
                            "role": "tool", 
                            "content": json.dumps(result)
                        })
                
                # Get final response from LLM with tool results
                final_response = await self.openai_client.chat.completions.create(
                    model="gpt-4-1106-preview",
                    messages=[
                        {
                            "role": "system",
                            "content": "You are a weather expert. Provide a natural, helpful response based on the weather data."
                        },
                        {
                            "role": "user",
                            "content": message
                        },
                        assistant_message,
                        *tool_results
                    ],
                    temperature=0.3
                )
                
                final_message = final_response.choices[0].message.content
                
            else:
                # LLM responded directly without tool calls
                final_message = assistant_message.content
            
            logger.info(f"‚úÖ LLM weather response generated successfully")
            
            return {
                'message': final_message,
                'status': 0,
                'conversation_id': conversation_id
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error in LLM weather processing: {e}")
            return {
                'message': f"Sorry, I encountered an error processing your weather request: {str(e)}",
                'status': -1,
                'conversation_id': conversation_id
            }

    async def _get_current_weather_api(self, location: str) -> Dict[str, Any]:
        """Get current weather for a location - REAL API ONLY (called by LLM tool)"""
        try:
            if not self.session:
                self.session = aiohttp.ClientSession()
            
            url = f"{self.base_url}/weather"
            params = {
                'q': location,
                'appid': self.weather_api_key,
                'units': 'metric'
            }
            
            logger.info(f"üå§Ô∏è Making REAL weather API call for: {location}")
            
            async with self.session.get(url, params=params, timeout=aiohttp.ClientTimeout(total=10)) as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"‚úÖ Successfully got REAL weather data for {location}")
                    return data
                else:
                    error_msg = f"Weather API error {response.status} for {location}"
                    logger.error(f"‚ùå {error_msg}")
                    raise Exception(error_msg)
                    
        except Exception as e:
            error_msg = f"Error calling weather API for {location}: {e}"
            logger.error(f"‚ùå {error_msg}")
            raise Exception(error_msg)

    async def _get_forecast_api(self, location: str) -> Dict[str, Any]:
        """Get weather forecast for a location - REAL API ONLY (called by LLM tool)"""
        try:
            if not self.session:
                self.session = aiohttp.ClientSession()
            
            url = f"{self.base_url}/forecast"
            params = {
                'q': location,
                'appid': self.weather_api_key,
                'units': 'metric'
            }
            
            logger.info(f"üå§Ô∏è Making REAL forecast API call for: {location}")
            
            async with self.session.get(url, params=params, timeout=aiohttp.ClientTimeout(total=10)) as response:
                if response.status == 200:
                    data = await response.json()
                    logger.info(f"‚úÖ Successfully got REAL forecast data for {location}")
                    return data
                else:
                    error_msg = f"Forecast API error {response.status} for {location}"
                    logger.error(f"‚ùå {error_msg}")
                    raise Exception(error_msg)
                    
        except Exception as e:
            error_msg = f"Error calling forecast API for {location}: {e}"
            logger.error(f"‚ùå {error_msg}")
            raise Exception(error_msg)

    async def close(self):
        """Clean up resources"""
        if self.session:
            await self.session.close()
        await super().close()

async def main():
    """Main entry point"""
    print("ü§ñ Starting LLM-Powered Weather Agent")
    print("====================================")
    print("‚úÖ Uses OpenAI GPT-4.1 for natural language processing")
    print("‚úÖ Uses LLM tool calls for weather API access")
    print("‚úÖ No regex parsing or keyword matching")
    print("‚úÖ Real API integration only")
    
    try:
        agent = LLMWeatherAgent()
        await agent.run()
    except KeyboardInterrupt:
        print("\nüõë Weather agent stopped by user")
    except Exception as e:
        print(f"‚ùå Error starting weather agent: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main()) 